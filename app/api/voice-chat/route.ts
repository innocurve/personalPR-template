import { NextResponse } from 'next/server'
import OpenAI from 'openai'
import { POST as chatHandler } from '../chat/route'

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
})

const ELEVEN_LABS_API_KEY = process.env.ELEVEN_LABS_API_KEY
const ELEVEN_LABS_VOICE_ID = process.env.ELEVEN_LABS_VOICE_ID

// ìŒì„± ê²€ì¦ì„ ìœ„í•œ ë¬´íš¨í•œ êµ¬ë¬¸ ëª©ë¡
const invalidPhrases = [
  'thanks for watching',
  'thank you for watching',
  'subscribe',
  'like and subscribe',
  'thank you',
  'Silence.',
  'bye.',
  "Oh, it's over.",
  'MBC ë‰´ìŠ¤ ì´ë•ì˜ì…ë‹ˆë‹¤.',
  'ë‹¤ìŒ ì˜ìƒì—ì„œ ë§Œë‚˜ìš”!',
  'Transcribed by',
  'transcribed using',
  'otter.ai',
  'powered by',
  'generated by',
  'you',
  'Bye! Bye!'
]

// í…ìŠ¤íŠ¸ ê²€ì¦ í•¨ìˆ˜
async function validateText(text: string) {
  // 1. ë¹ˆ í…ìŠ¤íŠ¸ ì²´í¬
  if (!text?.trim()) {
    throw new Error('í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.')
  }

  // 2. ì˜ë¯¸ ì—†ëŠ” í…ìŠ¤íŠ¸ ì²´í¬
  if (invalidPhrases.some(phrase => 
    text.toLowerCase().includes(phrase.toLowerCase())
  )) {
    throw new Error('ìœ íš¨í•˜ì§€ ì•Šì€ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.')
  }

  // 3. ë„ˆë¬´ ì§§ì€ í…ìŠ¤íŠ¸ ì²´í¬
  if (text.length < 2) {
    throw new Error('í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤.')
  }

  return text.trim()
}

// ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ ì¶”ê°€
async function generateErrorVoice(errorMessage: string) {
  const elevenLabsResponse = await fetch(
    `https://api.elevenlabs.io/v1/text-to-speech/${ELEVEN_LABS_VOICE_ID}`,
    {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Accept': 'audio/mpeg',
        'xi-api-key': ELEVEN_LABS_API_KEY!,
      },
      body: JSON.stringify({
        text: errorMessage,
        model_id: 'eleven_multilingual_v2',
        voice_settings: {
          stability: 0.5,
          similarity_boost: 1.0,
        },
      }),
    }
  )

  if (!elevenLabsResponse.ok) {
    throw new Error('ìŒì„± ì—ëŸ¬ ë©”ì‹œì§€ ìƒì„± ì‹¤íŒ¨')
  }

  return elevenLabsResponse.arrayBuffer()
}

export async function POST(req: Request) {
  try {
    // Content-Typeì„ í™•ì¸í•˜ì—¬ ì²˜ë¦¬ ë°©ì‹ ê²°ì •
    const contentType = req.headers.get('Content-Type')

    if (contentType?.includes('multipart/form-data')) {
      // ê¸°ì¡´ ë°©ì‹: ìŒì„± íŒŒì¼ ì²˜ë¦¬ (ChatInputì˜ ë§ˆì´í¬ ë²„íŠ¼)
      const formData = await req.formData()
      const audioFile = formData.get('audio') as File

      // Whisper APIë¡œ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
      const transcription = await openai.audio.transcriptions.create({
        file: audioFile,
        model: 'whisper-1',
      })
      
      // í…ìŠ¤íŠ¸ ê²€ì¦ ì¶”ê°€
      const validatedText = await validateText(transcription.text)
      const chatResponse = await handleChatRequest(validatedText)
      return chatResponse

    } else if (contentType?.includes('application/json')) {
      // ìƒˆë¡œìš´ ë°©ì‹: Web Speech APIì—ì„œ ì „ë‹¬ë°›ì€ í…ìŠ¤íŠ¸ ì²˜ë¦¬
      const { text } = await req.json()
      
      // í…ìŠ¤íŠ¸ ê²€ì¦ ì¶”ê°€
      const validatedText = await validateText(text)
      const chatResponse = await handleChatRequest(validatedText)
      return chatResponse
    }

    throw new Error('ì§€ì›í•˜ì§€ ì•ŠëŠ” Content-Typeì…ë‹ˆë‹¤.')

  } catch (error) {
    console.error('Voice chat error:', error)
    const errorAudio = await generateErrorVoice('ìŒì„± ì¸ì‹ì— ì‹¤íŒ¨í•˜ì˜€ìŠµë‹ˆë‹¤.')
    return new Response(errorAudio, {
      headers: {
        'Content-Type': 'audio/mpeg',
        'x-error': 'true',
      },
    })
  }
}

// Chat ìš”ì²­ ì²˜ë¦¬ë¥¼ ìœ„í•œ í—¬í¼ í•¨ìˆ˜
async function handleChatRequest(text: string) {
  console.log('ğŸ“ ì‚¬ìš©ì ì…ë ¥:', text)  // ì‚¬ìš©ì ì…ë ¥ ë¡œê·¸

  const chatRequest = new Request('http://localhost/api/chat', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      messages: [{ role: 'user', content: text }]
    }),
  })
  
  const chatResponse = await chatHandler(chatRequest)
  const chatData = await chatResponse.json()
  const responseText = chatData.content || chatData.message || chatData.response || text

  console.log('ğŸ’¬ AI ì‘ë‹µ:', responseText)  // AI ì‘ë‹µ ë¡œê·¸

  // ElevenLabsë¡œ ìŒì„± ë³€í™˜
  console.log('ğŸ”Š ìŒì„± ë³€í™˜ ì‹œì‘...')  // ìŒì„± ë³€í™˜ ì‹œì‘ ë¡œê·¸
  const elevenLabsResponse = await fetch(
    `https://api.elevenlabs.io/v1/text-to-speech/${ELEVEN_LABS_VOICE_ID}`,
    {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Accept': 'audio/mpeg',
        'xi-api-key': ELEVEN_LABS_API_KEY!,
      },
      body: JSON.stringify({
        text: responseText,
        model_id: 'eleven_multilingual_v2',
        voice_settings: {
          stability: 0.5,
          similarity_boost: 1.0,
        },
      }),
    }
  )

  console.log('âœ… ìŒì„± ë³€í™˜ ì™„ë£Œ')  // ìŒì„± ë³€í™˜ ì™„ë£Œ ë¡œê·¸
  const arrayBuffer = await elevenLabsResponse.arrayBuffer()
  return new Response(arrayBuffer, {
    headers: {
      'Content-Type': 'audio/mpeg',
      'x-transcription': encodeURIComponent(text),
      'x-response-text': encodeURIComponent(responseText),
    },
  })
} 