import { NextResponse } from 'next/server'
import OpenAI from 'openai'
import { POST as chatHandler } from '../chat/route'

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
})

const ELEVEN_LABS_API_KEY = process.env.ELEVEN_LABS_API_KEY
const ELEVEN_LABS_VOICE_ID = process.env.ELEVEN_LABS_VOICE_ID

// 음성 검증을 위한 무효한 구문 목록
const invalidPhrases = [
  'thanks for watching',
  'thank you for watching',
  'subscribe',
  'like and subscribe',
  'thank you',
  'Silence.',
  'bye.',
  "Oh, it's over.",
  'MBC 뉴스 이덕영입니다.',
  '다음 영상에서 만나요!',
  'Transcribed by',
  'transcribed using',
  'otter.ai',
  'powered by',
  'generated by',
  'you',
  'Bye! Bye!'
]

// 텍스트 검증 함수
async function validateText(text: string) {
  // 1. 빈 텍스트 체크
  if (!text?.trim()) {
    throw new Error('텍스트가 비어있습니다.')
  }

  // 2. 의미 없는 텍스트 체크
  if (invalidPhrases.some(phrase => 
    text.toLowerCase().includes(phrase.toLowerCase())
  )) {
    throw new Error('유효하지 않은 텍스트입니다.')
  }

  // 3. 너무 짧은 텍스트 체크
  if (text.length < 2) {
    throw new Error('텍스트가 너무 짧습니다.')
  }

  return text.trim()
}

// 에러 메시지를 음성으로 변환하는 함수 추가
async function generateErrorVoice(errorMessage: string) {
  const elevenLabsResponse = await fetch(
    `https://api.elevenlabs.io/v1/text-to-speech/${ELEVEN_LABS_VOICE_ID}`,
    {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Accept': 'audio/mpeg',
        'xi-api-key': ELEVEN_LABS_API_KEY!,
      },
      body: JSON.stringify({
        text: errorMessage,
        model_id: 'eleven_multilingual_v2',
        voice_settings: {
          stability: 0.5,
          similarity_boost: 1.0,
        },
      }),
    }
  )

  if (!elevenLabsResponse.ok) {
    throw new Error('음성 에러 메시지 생성 실패')
  }

  return elevenLabsResponse.arrayBuffer()
}

export async function POST(req: Request) {
  try {
    // Content-Type을 확인하여 처리 방식 결정
    const contentType = req.headers.get('Content-Type')

    if (contentType?.includes('multipart/form-data')) {
      // 기존 방식: 음성 파일 처리 (ChatInput의 마이크 버튼)
      const formData = await req.formData()
      const audioFile = formData.get('audio') as File

      // Whisper API로 음성을 텍스트로 변환
      const transcription = await openai.audio.transcriptions.create({
        file: audioFile,
        model: 'whisper-1',
      })
      
      // 텍스트 검증 추가
      const validatedText = await validateText(transcription.text)
      const chatResponse = await handleChatRequest(validatedText)
      return chatResponse

    } else if (contentType?.includes('application/json')) {
      // 새로운 방식: Web Speech API에서 전달받은 텍스트 처리
      const { text } = await req.json()
      
      // 텍스트 검증 추가
      const validatedText = await validateText(text)
      const chatResponse = await handleChatRequest(validatedText)
      return chatResponse
    }

    throw new Error('지원하지 않는 Content-Type입니다.')

  } catch (error) {
    console.error('Voice chat error:', error)
    const errorAudio = await generateErrorVoice('음성 인식에 실패하였습니다.')
    return new Response(errorAudio, {
      headers: {
        'Content-Type': 'audio/mpeg',
        'x-error': 'true',
      },
    })
  }
}

// Chat 요청 처리를 위한 헬퍼 함수
async function handleChatRequest(text: string) {
  console.log('📝 사용자 입력:', text)  // 사용자 입력 로그

  const chatRequest = new Request('http://localhost/api/chat', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      messages: [{ role: 'user', content: text }]
    }),
  })
  
  const chatResponse = await chatHandler(chatRequest)
  const chatData = await chatResponse.json()
  const responseText = chatData.content || chatData.message || chatData.response || text

  console.log('💬 AI 응답:', responseText)  // AI 응답 로그

  // ElevenLabs로 음성 변환
  console.log('🔊 음성 변환 시작...')  // 음성 변환 시작 로그
  const elevenLabsResponse = await fetch(
    `https://api.elevenlabs.io/v1/text-to-speech/${ELEVEN_LABS_VOICE_ID}`,
    {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Accept': 'audio/mpeg',
        'xi-api-key': ELEVEN_LABS_API_KEY!,
      },
      body: JSON.stringify({
        text: responseText,
        model_id: 'eleven_multilingual_v2',
        voice_settings: {
          stability: 0.5,
          similarity_boost: 1.0,
        },
      }),
    }
  )

  console.log('✅ 음성 변환 완료')  // 음성 변환 완료 로그
  const arrayBuffer = await elevenLabsResponse.arrayBuffer()
  return new Response(arrayBuffer, {
    headers: {
      'Content-Type': 'audio/mpeg',
      'x-transcription': encodeURIComponent(text),
      'x-response-text': encodeURIComponent(responseText),
    },
  })
} 