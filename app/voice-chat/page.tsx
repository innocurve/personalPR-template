'use client'

import { useState, useRef, useEffect } from 'react'
import { ArrowLeft, Moon, Sun, Mic, MicOff } from 'lucide-react'
import Link from 'next/link'
import Image from 'next/image'
import { motion, AnimatePresence } from 'framer-motion'
import { useLanguage } from '../contexts/LanguageContext'
import { useTheme } from '../contexts/ThemeContext'
import { translate, translateVoiceChat } from '../utils/translations'
import { useAudio } from '../contexts/AudioContext'
import Navigation from '../components/Navigation'

// íŒŒì¼ ìƒë‹¨ì— íƒ€ì… ì •ì˜ ì¶”ê°€
interface SpeechRecognitionEvent {
  resultIndex: number
  results: {
    [key: number]: {
      [key: number]: {
        transcript: string
      }
      isFinal: boolean
    }
  }
}

interface SpeechRecognitionErrorEvent {
  error: string
}

interface SpeechRecognition extends EventTarget {
  continuous: boolean
  interimResults: boolean
  lang: string
  start: () => void
  stop: () => void
  onstart: () => void
  onend: () => void
  onerror: (event: SpeechRecognitionErrorEvent) => void
  onresult: (event: SpeechRecognitionEvent) => void
}

declare global {
  interface Window {
    SpeechRecognition: new () => SpeechRecognition
    webkitSpeechRecognition: new () => SpeechRecognition
  }
}

// ëª¨ë°”ì¼ ë””ë°”ì´ìŠ¤ ê°ì§€ í•¨ìˆ˜
const isMobile = () => {
  if (typeof window === 'undefined') return false;
  return /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
};

// iOS ë””ë°”ì´ìŠ¤ ê°ì§€ í•¨ìˆ˜
const isIOS = () => {
  if (typeof window === 'undefined') return false;
  return /iPad|iPhone|iPod/.test(navigator.userAgent) || 
    (navigator.platform === 'MacIntel' && navigator.maxTouchPoints > 1);
};

// ì•ˆë“œë¡œì´ë“œ ë””ë°”ì´ìŠ¤ ê°ì§€ í•¨ìˆ˜
const isAndroid = () => {
  if (typeof window === 'undefined') return false;
  return /Android/i.test(navigator.userAgent);
};

// ì•ˆë“œë¡œì´ë“œ í¬ë¡¬ì—ì„œ ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ í™œì„±í™”ë¥¼ ìœ„í•œ í•¨ìˆ˜
const unlockAudioContext = async (audioContext: AudioContext) => {
  if (audioContext.state === 'suspended' && isAndroid()) {
    const unlockEvents = ['touchstart', 'touchend', 'mousedown', 'mouseup', 'click'];
    
    const unlock = async () => {
      await audioContext.resume();
      console.log('ì•ˆë“œë¡œì´ë“œì—ì„œ AudioContext í™œì„±í™”ë¨');
      
      // ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ì œê±°
      unlockEvents.forEach((event) => {
        document.body.removeEventListener(event, unlock);
      });
    };
    
    // ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ë“±ë¡
    unlockEvents.forEach((event) => {
      document.body.addEventListener(event, unlock, false);
    });
    
    // ë¹ˆ ë²„í¼ ì¬ìƒìœ¼ë¡œ ì˜¤ë””ì˜¤ ì‹œìŠ¤í…œ í™œì„±í™” ì‹œë„
    try {
      const buffer = audioContext.createBuffer(1, 1, 22050);
      const source = audioContext.createBufferSource();
      source.buffer = buffer;
      source.connect(audioContext.destination);
      source.start(0);
    } catch (e) {
      console.error('ì•ˆë“œë¡œì´ë“œì—ì„œ ì˜¤ë””ì˜¤ ì‹œìŠ¤í…œ í™œì„±í™” ì‹¤íŒ¨:', e);
    }
  }
};

export default function VoiceChatPage() {
  const { language } = useLanguage()
  const { isDarkMode, toggleDarkMode } = useTheme()
  
  // ìŒì„± ëŒ€í™” ê´€ë ¨ ìƒíƒœ ì¶”ê°€
  const [isListening, setIsListening] = useState(false)
  const [isTalking, setIsTalking] = useState(false)
  const [transcript, setTranscript] = useState("")
  const [isProcessing, setIsProcessing] = useState(false)
  const [conversationActive, setConversationActive] = useState(false)
  const [isPaused, setIsPaused] = useState(false)
  const [errorMessage, setErrorMessage] = useState<string | null>(null)
  const [permissionGranted, setPermissionGranted] = useState(false)
  
  // Refs
  const audioContextRef = useRef<AudioContext | null>(null)
  const analyserRef = useRef<AnalyserNode | null>(null)
  const mediaStreamRef = useRef<MediaStream | null>(null)
  const silenceTimeoutRef = useRef<NodeJS.Timeout | null>(null)
  const recognitionRef = useRef<SpeechRecognition | null>(null)
  const audioPlayerRef = useRef<HTMLAudioElement | null>(null)
  const isListeningRef = useRef(isListening)
  const isProcessingRef = useRef(isProcessing)
  const isPausedRef = useRef(isPaused)
  const conversationActiveRef = useRef(conversationActive)
  const permissionGrantedRef = useRef(permissionGranted)
  const notAllowedErrorCount = useRef(0)
  const restartTimerRef = useRef<NodeJS.Timeout | null>(null)

  // ìŒì„± ê°ì§€ ì„¤ì •
  const SILENCE_THRESHOLD = 15 // ë¬µìŒ ì„ê³„ê°’
  const SILENCE_DURATION = 1500 // ë¬µìŒ ì§€ì† ì‹œê°„ (1.5ì´ˆ)

  // ìŒì„± íŒŒí˜• ë°”ë“¤ì˜ ì• ë‹ˆë©”ì´ì…˜ì„ ìœ„í•œ ì„¤ì •
  const bars = Array.from({ length: 30 }) // 30ê°œì˜ íŒŒí˜• ë°”
  const getRandomHeight = () => Math.random() * 50 + 10 // 10-60px ì‚¬ì´ì˜ ëœë¤ ë†’ì´

  // SpeechRecognition ì„¤ì • í•¨ìˆ˜ ìˆ˜ì •
  const setupSpeechRecognition = () => {
    try {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition
      if (!SpeechRecognition) {
        throw new Error('Speech Recognition is not supported in this browser')
      }

      const recognition = new SpeechRecognition()
      
      recognition.lang = language === 'ko' ? 'ko-KR' : 'en-US'
      recognition.continuous = false  // ì—°ì† ì¸ì‹ ë¹„í™œì„±í™”
      recognition.interimResults = true
      
      recognition.onstart = () => {
        console.log('ìŒì„± ì¸ì‹ ì‹œì‘')
        setIsListening(true)
        
        // ëª¨ë°”ì¼ ê¸°ê¸°ì—ì„œ ìŒì„± ì¸ì‹ ì‹œì‘ ì‹œ ì¶”ê°€ ì²˜ë¦¬
        if (isMobile()) {
          console.log(`${isIOS() ? 'iOS' : 'ì•ˆë“œë¡œì´ë“œ'}ì—ì„œ ìŒì„± ì¸ì‹ ì‹œì‘ë¨`);
          
          // ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì¬ê°œ ì‹œë„
          if (audioContextRef.current && audioContextRef.current.state === 'suspended') {
            audioContextRef.current.resume().catch(err => {
              console.error('ëª¨ë°”ì¼ì—ì„œ AudioContext ì¬ê°œ ì‹¤íŒ¨:', err);
            });
            
            // ì•ˆë“œë¡œì´ë“œì—ì„œ ì¶”ê°€ ì²˜ë¦¬
            if (isAndroid() && audioContextRef.current) {
              unlockAudioContext(audioContextRef.current).catch(err => {
                console.error('ì•ˆë“œë¡œì´ë“œì—ì„œ AudioContext í™œì„±í™” ì‹¤íŒ¨:', err);
              });
            }
          }
        }
      }
      
      recognition.onresult = (event) => {
        const current = event.resultIndex
        const transcript = event.results[current][0].transcript
        
        console.log('ìŒì„± ì¸ì‹ ì¤‘:', transcript)
        setTranscript(transcript)
        
        if (event.results[current].isFinal) {
          console.log('ğŸ¤ ìµœì¢… ìŒì„± ì¸ì‹ ê²°ê³¼:', transcript)
          handleSpeechResult(transcript)
        }
      }
      
      recognition.onerror = (event) => {
        console.error('ìŒì„± ì¸ì‹ ì˜¤ë¥˜:', event.error)
        
        // ëª¨ë°”ì¼ì—ì„œ ì˜¤ë¥˜ ì²˜ë¦¬
        if (isMobile()) {
          console.log(`ëª¨ë°”ì¼ì—ì„œ ìŒì„± ì¸ì‹ ì˜¤ë¥˜ ë°œìƒ: ${event.error}`);
          
          // ì˜¤ë¥˜ ìœ í˜•ë³„ ë©”ì‹œì§€ ì„¤ì •
          let errorMsg = '';
          let shouldRetry = false;
          
          switch (event.error) {
            case 'not-allowed':
              if (isIOS()) {
                // iOSì—ì„œ not-allowed ì˜¤ë¥˜ ì¹´ìš´íŠ¸ ì¦ê°€
                notAllowedErrorCount.current += 1;
                console.log(`iOSì—ì„œ not-allowed ì˜¤ë¥˜ ë°œìƒ (${notAllowedErrorCount.current}/3)`);
                
                if (notAllowedErrorCount.current >= 3) {
                  errorMsg = 'ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œ ë¬¸ì œê°€ ì§€ì†ë©ë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.';
                  shouldRetry = false;
                } else {
                  errorMsg = 'ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ì„¤ì •ì—ì„œ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.';
                  shouldRetry = true;
                }
              } else if (isAndroid()) {
                errorMsg = 'ì•ˆë“œë¡œì´ë“œì—ì„œëŠ” ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì•¼ í•©ë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.';
                shouldRetry = true;
              } else {
                errorMsg = 'ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ì„¤ì •ì—ì„œ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.';
                shouldRetry = true;
              }
              break;
            case 'network':
              errorMsg = 'ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.';
              shouldRetry = true;
              break;
            case 'aborted':
              // iOSì—ì„œëŠ” aborted ì˜¤ë¥˜ê°€ ìì£¼ ë°œìƒí•˜ë¯€ë¡œ íŠ¹ë³„ ì²˜ë¦¬
              if (isIOS()) {
                console.log('iOSì—ì„œ aborted ì˜¤ë¥˜ ë°œìƒ, ì¬ì‹œì‘ ì‹œë„...');
                shouldRetry = true;
                errorMsg = ''; // ì˜¤ë¥˜ ë©”ì‹œì§€ í‘œì‹œí•˜ì§€ ì•ŠìŒ
              } else {
                // ë‹¤ë¥¸ ê¸°ê¸°ì—ì„œëŠ” ì‚¬ìš©ìê°€ ì˜ë„ì ìœ¼ë¡œ ì¤‘ë‹¨í•œ ê²½ìš°ë¡œ ê°„ì£¼
                return;
              }
              break;
            case 'audio-capture':
              errorMsg = 'ë§ˆì´í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë§ˆì´í¬ê°€ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.';
              break;
            case 'service-not-allowed':
              errorMsg = 'ìŒì„± ì¸ì‹ ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.';
              break;
            default:
              errorMsg = `ìŒì„± ì¸ì‹ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ${event.error}`;
          }
          
          // ì‚¬ìš©ìì—ê²Œ ì˜¤ë¥˜ ë©”ì‹œì§€ í‘œì‹œ
          setErrorMessage(errorMsg);
          
          // ì¬ì‹œë„ ì—¬ë¶€ ê²°ì •
          if (shouldRetry && conversationActiveRef.current) {
            setTimeout(() => {
              if (conversationActiveRef.current) {
                restartRecognition();
              }
            }, 1500);
            return;
          }
        }
        
        stopListening()
      }
      
      recognition.onend = () => {
        console.log('ìŒì„± ì¸ì‹ ì¢…ë£Œ')
        // ìŒì„± ì¸ì‹ì´ ì¢…ë£Œë˜ì—ˆì„ ë•Œ ìë™ìœ¼ë¡œ ì¬ì‹œì‘í•˜ì§€ ì•ŠìŒ
        // ëŒ€ì‹  handleSpeechResultì—ì„œ AI ì‘ë‹µ í›„ restartRecognitionì„ í˜¸ì¶œ
      }

      recognitionRef.current = recognition
      return recognition
    } catch (error) {
      console.error('Speech Recognition ì„¤ì • ì˜¤ë¥˜:', error)
      return null
    }
  }

  // handleSpeechResult í•¨ìˆ˜ ìˆ˜ì •
  const handleSpeechResult = async (text: string) => {
    if (!text.trim() || isProcessing) return
    
    console.log('ìŒì„± ì¸ì‹ ê²°ê³¼ ì²˜ë¦¬ ì‹œì‘, conversationActive:', conversationActiveRef.current);
    if (!conversationActiveRef.current) {
      console.log('ëŒ€í™”ê°€ í™œì„±í™”ë˜ì§€ ì•Šì•„ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ');
      return;
    }
    
    setIsProcessing(true)
    try {
      // ìŒì„± ì¸ì‹ ì¼ì‹œ ì¤‘ì§€ (but keep isListening true)
      if (recognitionRef.current) {
        try {
          recognitionRef.current.stop();
          setIsPaused(true);
          console.log('ìŒì„± ì¸ì‹ ì¼ì‹œ ì¤‘ì§€: recognition paused during AI response');
          console.log('isPaused ìƒíƒœë¥¼ trueë¡œ ì„¤ì •');
        } catch (err) {
          console.error('ìŒì„± ì¸ì‹ ì¤‘ì§€ ì¤‘ ì˜¤ë¥˜:', err);
        }
      }

      const response = await fetch('/api/voice-chat', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ text })
      })

      if (!response.ok) throw new Error('API ì‘ë‹µ ì˜¤ë¥˜')

      const audioBlob = await response.blob()
      await playAudio(audioBlob)

      console.log('AI ì‘ë‹µ ì¬ìƒ ì™„ë£Œ');

    } catch (error) {
      if (error instanceof Error) {
        console.warn('ìŒì„± ì²˜ë¦¬ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤:', error.message)
      }
    } finally {
      setIsProcessing(false)
      
      // isProcessingì´ falseë¡œ ì„¤ì •ëœ í›„ì— ì¬ì‹œì‘ ë¡œì§ ì‹¤í–‰
      if (conversationActiveRef.current) {
        console.log('finally ë¸”ë¡ì—ì„œ ì¬ì‹œì‘ ë¡œì§ ì‹¤í–‰, conversationActive:', conversationActiveRef.current);
        // ìƒíƒœ ì—…ë°ì´íŠ¸ê°€ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì´ë£¨ì–´ì§€ë¯€ë¡œ, ì•½ê°„ì˜ ì§€ì—° í›„ ì¬ì‹œì‘
        setTimeout(() => {
          console.log('finally ë¸”ë¡ì˜ íƒ€ì„ì•„ì›ƒì—ì„œ ì¬ì‹œì‘ ì‹œë„');
          console.log('ì¬ì‹œì‘ ì§ì „ ìƒíƒœ - conversationActive:', conversationActiveRef.current, 'isPaused:', isPaused);
          restartRecognition();
        }, 800); // 0.8ì´ˆë¡œ ì¤„ì„
      } else {
        console.log('ëŒ€í™”ê°€ í™œì„±í™”ë˜ì§€ ì•Šì•„ ì¬ì‹œì‘í•˜ì§€ ì•ŠìŒ, conversationActive:', conversationActiveRef.current);
      }
    }
  }

  // startListening í•¨ìˆ˜ ìˆ˜ì • - iOSì—ì„œ ì˜¤ë””ì˜¤ ê¶Œí•œ í™•ë³´ ë° ìŒì„± ì¸ì‹ ì‹œì‘ ê³¼ì • ê°œì„ 
  const startListening = async () => {
    try {
      console.log('ëŒ€í™” ì‹œì‘í•˜ê¸° ë²„íŠ¼ í´ë¦­ë¨');
      setErrorMessage(null); // ì˜¤ë¥˜ ë©”ì‹œì§€ ì´ˆê¸°í™”
      setConversationActive(true);
      conversationActiveRef.current = true; // ì¦‰ì‹œ ref ì—…ë°ì´íŠ¸
      console.log('conversationActive ìƒíƒœë¥¼ trueë¡œ ì„¤ì • (ref:', conversationActiveRef.current, ')');
      
      // ê¸°ì¡´ ë¦¬ì†ŒìŠ¤ ì •ë¦¬
      if (recognitionRef.current) {
        try {
          recognitionRef.current.stop();
          recognitionRef.current = null;
        } catch (err) {
          console.warn('ê¸°ì¡´ ìŒì„± ì¸ì‹ ì¤‘ì§€ ì¤‘ ì˜¤ë¥˜:', err);
        }
      }
      
      // ëª¨ë°”ì¼ ê¸°ê¸°ì—ì„œ ê¶Œí•œ í™•ë³´ ë° ì´ˆê¸°í™”
      if (isMobile()) {
        try {
          // iOSì—ì„œ ì˜¤ë””ì˜¤ ê¶Œí•œ í™•ë³´
          if (isIOS()) {
            console.log('iOSì—ì„œ ì˜¤ë””ì˜¤ ê¶Œí•œ í™•ë³´ ì‹œë„');
            await unlockAudioOnIOS();
            // not-allowed ì˜¤ë¥˜ ì¹´ìš´í„° ì´ˆê¸°í™”
            notAllowedErrorCount.current = 0;
          }
          
          // ëª¨ë°”ì¼ì—ì„œ ë§ˆì´í¬ ê¶Œí•œ í™•ë³´ë¥¼ ìœ„í•œ ì´ˆê¸° getUserMedia í˜¸ì¶œ
          console.log('ëª¨ë°”ì¼ ê¸°ê¸°ì—ì„œ ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œ í™•ë³´ ì‹œë„');
          const constraints = {
            audio: {
              echoCancellation: true,
              noiseSuppression: true,
              autoGainControl: true
            }
          };
          
          // ë§ˆì´í¬ ê¶Œí•œ ë¯¸ë¦¬ ìš”ì²­
          const stream = await navigator.mediaDevices.getUserMedia(constraints);
          
          // ê¸°ì¡´ ìŠ¤íŠ¸ë¦¼ì´ ìˆìœ¼ë©´ ì •ë¦¬
          if (mediaStreamRef.current) {
            mediaStreamRef.current.getTracks().forEach(track => track.stop());
          }
          
          // ìƒˆ ìŠ¤íŠ¸ë¦¼ ì €ì¥
          mediaStreamRef.current = stream;
          console.log('ëª¨ë°”ì¼ ê¸°ê¸°ì—ì„œ ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œ í™•ë³´ ì„±ê³µ');
          
          // ì•½ê°„ì˜ ì§€ì—° í›„ ìŒì„± ì¸ì‹ ì‹œì‘ (iOSì—ì„œ ë” ì•ˆì •ì )
          await new Promise(resolve => setTimeout(resolve, 300));
        } catch (err) {
          console.error('ëª¨ë°”ì¼ ê¸°ê¸°ì—ì„œ ê¶Œí•œ í™•ë³´ ì‹¤íŒ¨:', err);
          setErrorMessage('ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.');
          return; // ê¶Œí•œ í™•ë³´ ì‹¤íŒ¨ ì‹œ í•¨ìˆ˜ ì¢…ë£Œ
        }
      }

      // ì˜¤ë””ì˜¤ ë¶„ì„ ì„¤ì • - ëª¨ë°”ì¼ ê¸°ê¸°ì— ìµœì í™”ëœ ì„¤ì •
      const constraints = {
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      };
      
      // ëª¨ë°”ì¼ ê¸°ê¸°ì—ì„œ ì¶”ê°€ ì„¤ì •
      if (isMobile()) {
        console.log('ëª¨ë°”ì¼ ê¸°ê¸°ì—ì„œ ë§ˆì´í¬ ì ‘ê·¼ ì‹œë„');
        // ëª¨ë°”ì¼ ê¸°ê¸°ì—ì„œëŠ” ê¸°ë³¸ ì„¤ì • ì‚¬ìš©
      }
      
      const stream = await navigator.mediaDevices.getUserMedia(constraints)
      mediaStreamRef.current = stream
      
      // ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì„¤ì • ë¶€ë¶„ ìˆ˜ì •
      const AudioContextClass = window.AudioContext || (window as any).webkitAudioContext;
      const audioContext = new AudioContextClass();
      
      // ëª¨ë°”ì¼ ê¸°ê¸°ì—ì„œ ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ìƒíƒœ í™•ì¸ ë° ì¬ê°œ
      if (audioContext.state === 'suspended') {
        try {
          await audioContext.resume();
          console.log('AudioContext ì¬ê°œë¨');
          
          // ëª¨ë°”ì¼ ê¸°ê¸°ì—ì„œëŠ” ì¶”ê°€ ì²˜ë¦¬
          if (isMobile()) {
            if (isAndroid()) {
              // ì•ˆë“œë¡œì´ë“œì—ì„œ ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ í™œì„±í™”
              await unlockAudioContext(audioContext);
            } else {
              // iOS ë° ê¸°íƒ€ ëª¨ë°”ì¼ ë¸Œë¼ìš°ì €ì—ì„œëŠ” ì‚¬ìš©ì ìƒí˜¸ì‘ìš© í›„ ì§§ì€ ì†Œë¦¬ë¥¼ ì¬ìƒí•˜ì—¬ ì˜¤ë””ì˜¤ ì‹œìŠ¤í…œ í™œì„±í™”
              try {
                const silentContext = new AudioContextClass();
                const buffer = silentContext.createBuffer(1, 1, 22050);
                const source = silentContext.createBufferSource();
                source.buffer = buffer;
                source.connect(silentContext.destination);
                source.start(0);
                console.log('ëª¨ë°”ì¼ ê¸°ê¸°ì—ì„œ ì˜¤ë””ì˜¤ ì‹œìŠ¤í…œ í™œì„±í™” ì‹œë„');
              } catch (silentErr) {
                console.error('ì˜¤ë””ì˜¤ ì‹œìŠ¤í…œ í™œì„±í™” ì‹¤íŒ¨:', silentErr);
              }
            }
          }
        } catch (err) {
          console.error('AudioContext ì¬ê°œ ì‹¤íŒ¨:', err);
        }
      }
      
      const analyser = audioContext.createAnalyser()
      const source = audioContext.createMediaStreamSource(stream)
      
      analyser.fftSize = 2048
      source.connect(analyser)
      
      audioContextRef.current = audioContext
      analyserRef.current = analyser
      
      setIsListening(true)
      monitorAudioLevel()
      
      // Speech Recognition ìƒˆë¡œ ì„¤ì • ë° ì‹œì‘
      const recognition = setupSpeechRecognition();
      if (recognition) {
        recognition.start();
      }
      
    } catch (error) {
      console.error('ìŒì„± ì¸ì‹ ì‹œì‘ ì˜¤ë¥˜:', error)
      stopListening()
    }
  }

  const monitorAudioLevel = () => {
    if (!analyserRef.current) return

    const analyser = analyserRef.current
    const dataArray = new Uint8Array(analyser.frequencyBinCount)
    
    const checkLevel = () => {
      if (!isListening) return
      
      analyser.getByteFrequencyData(dataArray)
      const average = dataArray.reduce((acc, val) => acc + val, 0) / dataArray.length
      
      if (average > SILENCE_THRESHOLD) {
        // ìŒì„± ê°ì§€ë¨
        setIsTalking(true)
        if (silenceTimeoutRef.current) {
          clearTimeout(silenceTimeoutRef.current)
          silenceTimeoutRef.current = null
        }
      } else if (isTalking) {
        // ë¬µìŒ ê°ì§€
        if (!silenceTimeoutRef.current) {
          silenceTimeoutRef.current = setTimeout(() => {
            handleSpeechEnd()
          }, SILENCE_DURATION)
        }
      }
      
      requestAnimationFrame(checkLevel)
    }
    
    checkLevel()
  }

  const handleSpeechEnd = async () => {
    setIsTalking(false)
    // transcriptê°€ ì´ë¯¸ handleSpeechResultì—ì„œ ì²˜ë¦¬ë˜ì—ˆìœ¼ë¯€ë¡œ
    // ì—¬ê¸°ì„œëŠ” ìƒíƒœë§Œ ì´ˆê¸°í™”
    setTranscript("")
  }

  // stopListening í•¨ìˆ˜ ìˆ˜ì •
  const stopListening = () => {
    try {
      setConversationActive(false); // ëŒ€í™” í™œì„±í™” ìƒíƒœë¥¼ falseë¡œ ì„¤ì •
      conversationActiveRef.current = false; // ì¦‰ì‹œ ref ì—…ë°ì´íŠ¸
      console.log('ëŒ€í™” ì¢…ë£Œ: conversationActiveë¥¼ falseë¡œ ì„¤ì •');
      setIsProcessing(false) // ë¨¼ì € ì²˜ë¦¬ ìƒíƒœë¥¼ falseë¡œ ì„¤ì •

      // 1. í˜„ì¬ ì¬ìƒ ì¤‘ì¸ ì˜¤ë””ì˜¤ ì¤‘ì§€ - ì—ëŸ¬ ì²˜ë¦¬ ì¶”ê°€
      if (audioPlayerRef.current) {
        try {
          audioPlayerRef.current.pause();
          audioPlayerRef.current.src = '';
          audioPlayerRef.current = null;
        } catch (err) {
          // ì˜¤ë””ì˜¤ ì¤‘ì§€ ì¤‘ ì—ëŸ¬ëŠ” ë¬´ì‹œ
        }
      }

      // 2. Web Speech Recognition ì¤‘ì§€
      if (recognitionRef.current) {
        try {
          recognitionRef.current.stop()
          // ë¹ˆ í•¨ìˆ˜ë¡œ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì´ˆê¸°í™”
          recognitionRef.current.onend = () => {};
          recognitionRef.current.onresult = () => {};
          recognitionRef.current.onerror = () => {};
          recognitionRef.current = null
        } catch (err) {
          // Recognition ì¤‘ì§€ ì¤‘ ì—ëŸ¬ëŠ” ë¬´ì‹œ
        }
      }

      // 3. ë¯¸ë””ì–´ ìŠ¤íŠ¸ë¦¼ íŠ¸ë™ ì¤‘ì§€
      if (mediaStreamRef.current) {
        try {
          mediaStreamRef.current.getTracks().forEach(track => {
            track.stop()
            mediaStreamRef.current?.removeTrack(track)
          })
          mediaStreamRef.current = null
        } catch (err) {
          // ë¯¸ë””ì–´ ìŠ¤íŠ¸ë¦¼ ì¤‘ì§€ ì¤‘ ì—ëŸ¬ëŠ” ë¬´ì‹œ
        }
      }

      // 4. AudioContext ì •ë¦¬
      if (audioContextRef.current) {
        try {
          audioContextRef.current.close()
          audioContextRef.current = null
        } catch (err) {
          // AudioContext ì¤‘ì§€ ì¤‘ ì—ëŸ¬ëŠ” ë¬´ì‹œ
        }
      }

      // 5. AnalyserNode ì—°ê²° í•´ì œ
      if (analyserRef.current) {
        try {
          analyserRef.current.disconnect()
          analyserRef.current = null
        } catch (err) {
          // Analyser ì—°ê²° í•´ì œ ì¤‘ ì—ëŸ¬ëŠ” ë¬´ì‹œ
        }
      }

      // 6. íƒ€ì´ë¨¸ ì •ë¦¬
      if (silenceTimeoutRef.current) {
        clearTimeout(silenceTimeoutRef.current)
        silenceTimeoutRef.current = null
      }

      // 7. ìƒíƒœ ì´ˆê¸°í™”
      setIsListening(false)
      setIsTalking(false)
      setTranscript("")

      console.log('ìŒì„± ëŒ€í™”ê°€ ì•ˆì „í•˜ê²Œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.')
    } catch (error) {
      console.warn('ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘ ì¼ë¶€ ì‘ì—…ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤:', error)
    }
  }

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
  useEffect(() => {
    return () => {
      stopListening()
    }
  }, [])

  // í˜ì´ì§€ ì´ë™ ì‹œ ì •ë¦¬ë¥¼ ìœ„í•œ ì¶”ê°€
  useEffect(() => {
    const handleBeforeUnload = () => {
      stopListening()
    }

    window.addEventListener('beforeunload', handleBeforeUnload)
    return () => {
      window.removeEventListener('beforeunload', handleBeforeUnload)
    }
  }, [])

  // playAudio í•¨ìˆ˜ ìˆ˜ì • - iOSì—ì„œ ì˜¤ë””ì˜¤ ì¬ìƒ ë¬¸ì œ í•´ê²°
  const playAudio = async (audioBlob: Blob): Promise<void> => {
    return new Promise((resolve, reject) => {
      try {
        // ì´ì „ ì˜¤ë””ì˜¤ ì •ë¦¬
        if (audioPlayerRef.current) {
          try {
            audioPlayerRef.current.pause();
            audioPlayerRef.current.src = '';
          } catch (err) {
            // ì´ì „ ì˜¤ë””ì˜¤ ì¤‘ì§€ ì¤‘ ì—ëŸ¬ëŠ” ë¬´ì‹œ
          }
        }
        
        // ì˜¤ë””ì˜¤ URL ìƒì„± ë° ì˜¤ë””ì˜¤ ê°ì²´ ì„¤ì •
        const audioUrl = URL.createObjectURL(audioBlob)
        const audio = new Audio(audioUrl)
        audioPlayerRef.current = audio;
        
        // ëª¨ë°”ì¼ ê¸°ê¸°ì—ì„œ ì˜¤ë””ì˜¤ ì¬ìƒ ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ì„¤ì •
        audio.preload = 'auto';
        
        // ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì„¤ì •
        audio.onended = () => {
          URL.revokeObjectURL(audioUrl)
          audioPlayerRef.current = null;
          resolve();
        }
        
        audio.onerror = (e) => {
          console.error('ì˜¤ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜:', e);
          URL.revokeObjectURL(audioUrl)
          audioPlayerRef.current = null;
          reject(new Error('ì˜¤ë””ì˜¤ ì¬ìƒì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.'))
        }
        
        // ëª¨ë°”ì¼ ê¸°ê¸°ì—ì„œ ì˜¤ë””ì˜¤ ì¬ìƒ ì „ ì¶”ê°€ ì„¤ì •
        if (isMobile()) {
          console.log('ëª¨ë°”ì¼ì—ì„œ ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œë„...');
          
          // ëª¨ë°”ì¼ ê¸°ê¸°ì—ì„œ ê³µí†µ ì„¤ì •
          audio.setAttribute('playsinline', '');
          audio.setAttribute('webkit-playsinline', '');
          
          // iOSì—ì„œ ì˜¤ë””ì˜¤ ì¬ìƒ ê¶Œí•œ í™•ë³´
          if (isIOS()) {
            console.log('iOSì—ì„œ ì˜¤ë””ì˜¤ ì¬ìƒ ì¤€ë¹„...');
            
            // iOSì—ì„œ ì˜¤ë””ì˜¤ ìš”ì†Œì— ì¶”ê°€ ì†ì„± ì„¤ì •
            audio.muted = true; // ì²˜ìŒì—ëŠ” ìŒì†Œê±°ë¡œ ì‹œì‘
            audio.volume = 0;
            (audio as any).playsInline = true;
            
            // ì´ë¯¸ ê¶Œí•œì´ í™•ë³´ë˜ì—ˆëŠ”ì§€ í™•ì¸
            if (!permissionGrantedRef.current) {
              console.log('iOSì—ì„œ ì˜¤ë””ì˜¤ ê¶Œí•œ ì¬í™•ë³´ ì‹œë„');
              unlockAudioOnIOS().catch(err => {
                console.error('iOSì—ì„œ ì˜¤ë””ì˜¤ ì¬ìƒ ê¶Œí•œ ì¬í™•ë³´ ì‹¤íŒ¨:', err);
                // ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
              });
            }
          }
          
          // ì§€ì—° í›„ ì¬ìƒ ì‹œë„
          setTimeout(() => {
            const playWithRetry = () => {
              const playPromise = isIOS() 
                ? (async () => {
                    // iOSì—ì„œëŠ” muted ìƒíƒœë¡œ ë¨¼ì € ì¬ìƒ
                    audio.muted = true;
                    await audio.play();
                    console.log('iOSì—ì„œ muted ìƒíƒœë¡œ ì˜¤ë””ì˜¤ ì¬ìƒ ì„±ê³µ');
                    
                    // ì ì‹œ í›„ unmute
                    setTimeout(() => {
                      audio.muted = false;
                      console.log('iOSì—ì„œ ì˜¤ë””ì˜¤ unmute ì™„ë£Œ');
                    }, 100);
                  })()
                : audio.play();
              
              playPromise.catch(err => {
                console.error('ì˜¤ë””ì˜¤ ì¬ìƒ ì²« ì‹œë„ ì‹¤íŒ¨:', err);
                
                // ì¬ì‹œë„
                setTimeout(() => {
                  // ë‘ ë²ˆì§¸ ì‹œë„ì—ì„œëŠ” ë‹¤ë¥¸ ë°©ì‹ ì‹œë„
                  if (isIOS()) {
                    // iOSì—ì„œ ë‹¤ì‹œ ê¶Œí•œ í™•ë³´ ì‹œë„
                    unlockAudioOnIOS()
                      .then(() => {
                        audio.muted = false; // ì§ì ‘ ì†Œë¦¬ ì¬ìƒ ì‹œë„
                        return audio.play();
                      })
                      .catch(retryErr => {
                        console.error('ì˜¤ë””ì˜¤ ì¬ìƒ ì¬ì‹œë„ ì‹¤íŒ¨:', retryErr);
                        reject(new Error('ì˜¤ë””ì˜¤ ì¬ìƒì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'));
                      });
                  } else {
                    audio.play().catch(retryErr => {
                      console.error('ì˜¤ë””ì˜¤ ì¬ìƒ ì¬ì‹œë„ ì‹¤íŒ¨:', retryErr);
                      reject(new Error('ì˜¤ë””ì˜¤ ì¬ìƒì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'));
                    });
                  }
                }, 300);
              });
            };
            
            playWithRetry();
          }, 500);
        } else {
          // ë°ìŠ¤í¬í†±ì—ì„œëŠ” ë°”ë¡œ ì¬ìƒ
          audio.play().catch(err => {
            console.error('ì˜¤ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨:', err);
            reject(new Error('ì˜¤ë””ì˜¤ ì¬ìƒì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'));
          });
        }
      } catch (error) {
        reject(new Error('ì˜¤ë””ì˜¤ ì¬ìƒ ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'))
      }
    })
  }

  // ìƒíƒœ ë³€ê²½ ì‹œ ref ì—…ë°ì´íŠ¸
  useEffect(() => {
    isListeningRef.current = isListening
  }, [isListening])

  useEffect(() => {
    isProcessingRef.current = isProcessing
  }, [isProcessing])

  useEffect(() => {
    isPausedRef.current = isPaused
  }, [isPaused])

  useEffect(() => {
    conversationActiveRef.current = conversationActive;
  }, [conversationActive]);

  useEffect(() => {
    permissionGrantedRef.current = permissionGranted;
  }, [permissionGranted]);

  // iOSì—ì„œ ì˜¤ë””ì˜¤ ì¬ìƒ ê¶Œí•œ í™•ë³´ë¥¼ ìœ„í•œ í•¨ìˆ˜
  const unlockAudioOnIOS = async () => {
    if (!isIOS()) return;
    
    console.log('iOSì—ì„œ ì˜¤ë””ì˜¤ ì¬ìƒ ê¶Œí•œ í™•ë³´ ì‹œë„...');
    
    try {
      // ì´ë¯¸ ê¶Œí•œì´ í™•ë³´ëœ ê²½ìš° ìŠ¤í‚µ
      if (permissionGrantedRef.current) {
        console.log('iOSì—ì„œ ì´ë¯¸ ì˜¤ë””ì˜¤ ê¶Œí•œì´ í™•ë³´ë˜ì–´ ìˆìŠµë‹ˆë‹¤.');
        return;
      }
      
      // ì§§ì€ ë¬´ìŒ ì˜¤ë””ì˜¤ ìƒì„± ë° ì¬ìƒ (iOS Safariì— ìµœì í™”)
      const AudioContext = window.AudioContext || (window as any).webkitAudioContext;
      const audioContext = new AudioContext();
      
      // ì‚¬ìš©ì ì œìŠ¤ì²˜ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ë‚´ì—ì„œ ì‹¤í–‰ë˜ì–´ì•¼ í•¨
      const buffer = audioContext.createBuffer(1, 1, 22050);
      const source = audioContext.createBufferSource();
      source.buffer = buffer;
      source.connect(audioContext.destination);
      
      // iOSì—ì„œëŠ” ì˜¤ë””ì˜¤ ìš”ì†Œë¥¼ í†µí•œ ì¬ìƒë„ í•„ìš”
      const silentAudio = new Audio();
      silentAudio.autoplay = true;
      silentAudio.muted = true;
      (silentAudio as any).playsInline = true;
      silentAudio.src = 'data:audio/wav;base64,UklGRigAAABXQVZFZm10IBIAAAABAAEARKwAAIhYAQACABAAAABkYXRhAgAAAAEA';
      
      // í•œ ë²ˆì— í•˜ë‚˜ì”© ì‹¤í–‰ (Promise.all ëŒ€ì‹ )
      try {
        await source.start(0);
        console.log('iOSì—ì„œ AudioContext ì†ŒìŠ¤ ì‹œì‘ ì„±ê³µ');
      } catch (sourceErr) {
        console.warn('iOSì—ì„œ AudioContext ì†ŒìŠ¤ ì‹œì‘ ì‹¤íŒ¨:', sourceErr);
      }
      
      try {
        await silentAudio.play();
        console.log('iOSì—ì„œ ë¬´ìŒ ì˜¤ë””ì˜¤ ì¬ìƒ ì„±ê³µ');
      } catch (audioErr) {
        console.warn('iOSì—ì„œ ë¬´ìŒ ì˜¤ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨:', audioErr);
        // ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
      }
      
      // ì„±ê³µìœ¼ë¡œ ê°„ì£¼
      console.log('iOSì—ì„œ ì˜¤ë””ì˜¤ ì¬ìƒ ê¶Œí•œ í™•ë³´ ì„±ê³µ');
      setPermissionGranted(true);
      
      // ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì°¸ì¡° ì €ì¥ (ë‚˜ì¤‘ì— ì¬ì‚¬ìš©)
      if (!audioContextRef.current) {
        audioContextRef.current = audioContext;
      }
      
      return audioContext;
    } catch (err) {
      console.error('iOSì—ì„œ ì˜¤ë””ì˜¤ ì¬ìƒ ê¶Œí•œ í™•ë³´ ì‹¤íŒ¨:', err);
      // ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰í•  ìˆ˜ ìˆë„ë¡ ì˜¤ë¥˜ë¥¼ ë‹¤ì‹œ throwí•˜ì§€ ì•ŠìŒ
    }
  };

  // restartRecognition í•¨ìˆ˜ ìˆ˜ì •
  const restartRecognition = () => {
    // ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ íƒ€ì´ë¨¸ê°€ ìˆìœ¼ë©´ ì·¨ì†Œ
    if (restartTimerRef.current) {
      clearTimeout(restartTimerRef.current);
    }
    
    // ìƒˆ íƒ€ì´ë¨¸ ì„¤ì •
    restartTimerRef.current = setTimeout(() => {
      try {
        // ê¸°ì¡´ ì¸ìŠ¤í„´ìŠ¤ ì •ë¦¬
        if (recognitionRef.current) {
          try {
            recognitionRef.current.stop();
          } catch (stopError) {
            console.warn('ê¸°ì¡´ ì¸ìŠ¤í„´ìŠ¤ ì¤‘ì§€ ì¤‘ ì˜¤ë¥˜:', stopError);
          }
          recognitionRef.current = null;
        }
        
        const recognition = setupSpeechRecognition();
        if (recognition) {
          console.log('ìƒˆ recognition ì¸ìŠ¤í„´ìŠ¤ ìƒì„±ë¨, ì‹œì‘ ì‹œë„...');
          recognition.start();
          recognitionRef.current = recognition;
          setIsListening(true); // ëª…ì‹œì ìœ¼ë¡œ isListening ì„¤ì •
          console.log('ì¬ì‹œì‘: Speech Recognition ì‹œì‘ë¨');
        } else {
          console.warn('ì¬ì‹œì‘: Speech Recognition ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨');
        }
      } catch (error) {
        console.error('ìŒì„± ì¸ì‹ ì¬ì‹œì‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:', error);
      }
    }, 200); // 0.2ì´ˆë¡œ ì¤„ì„
  };

  return (
    <div className={`min-h-screen flex flex-col ${isDarkMode ? 'bg-gray-900 text-white' : 'bg-gray-100 text-gray-900'}`}>
      {/* ë„¤ë¹„ê²Œì´ì…˜ */}
      <div className="fixed top-0 left-0 right-0 z-50 border-b border-gray-200 dark:border-gray-700 bg-white/80 dark:bg-gray-900/80 backdrop-blur-sm">
        <Navigation language={language} />
      </div>

      {/* ë©”ì¸ ì»¨í…ì¸  */}
      <main className="flex-1 max-w-5xl mx-auto w-full mt-24 p-8">
        <div className="flex flex-col items-center justify-center min-h-[calc(100vh-160px)]">
          <div className="w-32 h-32 relative rounded-full overflow-hidden mb-8 shadow-xl">
            <Image
              src="/profile.png"
              alt={translate('name', language)}
              fill
              sizes="(max-width: 768px) 128px, 128px"
              className="object-cover object-top"
            />
          </div>

          {/* ìŒì„± íŒŒí˜• ì• ë‹ˆë©”ì´ì…˜ - ìƒíƒœì— ë”°ë¼ ë‹¤ë¥´ê²Œ í‘œì‹œ */}
          <div className="flex items-center justify-center gap-1 mb-8 h-32">
            {bars.map((_, i) => (
              <motion.div
                key={i}
                className={`w-1 rounded-full ${
                  isTalking 
                    ? 'bg-green-500' 
                    : isDarkMode ? 'bg-blue-400' : 'bg-blue-500'
                }`}
                animate={{
                  height: isTalking 
                    ? [getRandomHeight() * 1.5, getRandomHeight() * 1.5] 
                    : isListening 
                      ? [getRandomHeight(), getRandomHeight()]
                      : "20px"
                }}
                transition={{
                  duration: isTalking ? 0.3 : 1.5,
                  repeat: Infinity,
                  repeatType: "reverse",
                  delay: i * 0.05,
                }}
              />
            ))}
          </div>

          {/* ìƒíƒœ ë©”ì‹œì§€ */}
          <div className={`text-center max-w-md mx-auto ${isDarkMode ? 'text-gray-300' : 'text-gray-700'}`}>
            <h2 className="text-3xl font-bold mb-4 whitespace-pre-line">
              {errorMessage 
                ? translate('error', language) || "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤"
                : isListening 
                  ? isTalking 
                    ? translateVoiceChat('recognizingVoice', language) || "ìŒì„±ì„ ì¸ì‹í•˜ê³  ìˆìŠµë‹ˆë‹¤..."
                    : translateVoiceChat('pleaseSpeak', language) || "ë§ì”€í•´ ì£¼ì„¸ìš”"
                : translateVoiceChat('voiceChatTitle', language).replace('{name}', `${translate('name', language)}${translate('cloneTitle', language)}`)}
            </h2>
            <p className={`text-lg ${errorMessage ? 'text-red-500 font-medium' : 'opacity-75'} whitespace-pre-line`}>
              {errorMessage 
                ? errorMessage
                : isListening 
                  ? isMobile() 
                    ? isIOS() 
                      ? translateVoiceChat('iosPermission', language) || "iOSì—ì„œëŠ” ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì•¼ í•©ë‹ˆë‹¤"
                      : translateVoiceChat('androidPermission', language) || "ì•ˆë“œë¡œì´ë“œì—ì„œëŠ” ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì•¼ í•©ë‹ˆë‹¤"
                    : translateVoiceChat('autoVoiceDetection', language) || "ìë™ìœ¼ë¡œ ìŒì„±ì„ ê°ì§€í•˜ì—¬ ëŒ€í™”í•©ë‹ˆë‹¤"
                  : translateVoiceChat('speakFreely', language) || "ììœ ë¡­ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”. ìë™ìœ¼ë¡œ ìŒì„±ì„ ì¸ì‹í•˜ì—¬ ëŒ€í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤."}
            </p>
          </div>

          {/* ëŒ€í™” ì‹œì‘/ì¢…ë£Œ ë²„íŠ¼ê³¼ ì±„íŒ…ìœ¼ë¡œ ëŒì•„ê°€ê¸° ë²„íŠ¼ */}
          <div className="mt-12 flex items-center gap-4">
            <Link href="/chat">
              <motion.button
                className={`px-6 py-4 rounded-full font-medium border-2 
                  ${isDarkMode 
                    ? 'border-gray-600 text-gray-300 hover:bg-gray-800' 
                    : 'border-gray-300 text-gray-700 hover:bg-gray-100'
                  } transform transition-all duration-200 hover:scale-105`}
                whileHover={{ scale: 1.05 }}
                whileTap={{ scale: 0.95 }}
              >
                {translate('backToChat', language) || "ì±„íŒ…ìœ¼ë¡œ ëŒì•„ê°€ê¸°"}
              </motion.button>
            </Link>
            
            <motion.button
              onClick={isListening ? stopListening : startListening}
              className={`px-8 py-4 rounded-full text-white font-medium
                ${isListening 
                  ? 'bg-red-500 hover:bg-red-600' 
                  : isDarkMode 
                    ? 'bg-blue-600 hover:bg-blue-700' 
                    : 'bg-blue-500 hover:bg-blue-600'
                } transform transition-all duration-200 hover:scale-105 shadow-lg`}
            >
              {isListening 
                ? translateVoiceChat('endConversation', language) || "ëŒ€í™” ì¢…ë£Œí•˜ê¸°"
                : translateVoiceChat('startConversation', language) || "ëŒ€í™” ì‹œì‘í•˜ê¸°"}
            </motion.button>
          </div>
        </div>
      </main>
    </div>
  )
}