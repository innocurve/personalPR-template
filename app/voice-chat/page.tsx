'use client'

import { useState, useRef, useEffect } from 'react'
import { ArrowLeft, Moon, Sun, Mic, MicOff } from 'lucide-react'
import Link from 'next/link'
import Image from 'next/image'
import { motion, AnimatePresence } from 'framer-motion'
import { useLanguage } from '../contexts/LanguageContext'
import { translate } from '../utils/translations'

// íŒŒì¼ ìƒë‹¨ì— íƒ€ì… ì •ì˜ ì¶”ê°€
interface SpeechRecognitionEvent {
  resultIndex: number
  results: {
    [key: number]: {
      [key: number]: {
        transcript: string
      }
      isFinal: boolean
    }
  }
}

interface SpeechRecognitionErrorEvent {
  error: string
}

interface SpeechRecognition extends EventTarget {
  continuous: boolean
  interimResults: boolean
  lang: string
  start: () => void
  stop: () => void
  onstart: () => void
  onend: () => void
  onerror: (event: SpeechRecognitionErrorEvent) => void
  onresult: (event: SpeechRecognitionEvent) => void
}

declare global {
  interface Window {
    SpeechRecognition: new () => SpeechRecognition
    webkitSpeechRecognition: new () => SpeechRecognition
  }
}

// ëª¨ë°”ì¼ ë””ë°”ì´ìŠ¤ ê°ì§€ í•¨ìˆ˜
const isMobile = () => {
  if (typeof window === 'undefined') return false;
  return /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
};

// iOS ë””ë°”ì´ìŠ¤ ê°ì§€ í•¨ìˆ˜
const isIOS = () => {
  if (typeof window === 'undefined') return false;
  return /iPad|iPhone|iPod/.test(navigator.userAgent) || 
    (navigator.platform === 'MacIntel' && navigator.maxTouchPoints > 1);
};

// ì•ˆë“œë¡œì´ë“œ ë””ë°”ì´ìŠ¤ ê°ì§€ í•¨ìˆ˜
const isAndroid = () => {
  if (typeof window === 'undefined') return false;
  return /Android/i.test(navigator.userAgent);
};

// ì•ˆë“œë¡œì´ë“œ í¬ë¡¬ì—ì„œ ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ í™œì„±í™”ë¥¼ ìœ„í•œ í•¨ìˆ˜
const unlockAudioContext = async (audioContext: AudioContext) => {
  if (audioContext.state === 'suspended' && isAndroid()) {
    const unlockEvents = ['touchstart', 'touchend', 'mousedown', 'mouseup', 'click'];
    
    const unlock = async () => {
      await audioContext.resume();
      console.log('ì•ˆë“œë¡œì´ë“œì—ì„œ AudioContext í™œì„±í™”ë¨');
      
      // ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ì œê±°
      unlockEvents.forEach((event) => {
        document.body.removeEventListener(event, unlock);
      });
    };
    
    // ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ë“±ë¡
    unlockEvents.forEach((event) => {
      document.body.addEventListener(event, unlock, false);
    });
    
    // ë¹ˆ ë²„í¼ ì¬ìƒìœ¼ë¡œ ì˜¤ë””ì˜¤ ì‹œìŠ¤í…œ í™œì„±í™” ì‹œë„
    try {
      const buffer = audioContext.createBuffer(1, 1, 22050);
      const source = audioContext.createBufferSource();
      source.buffer = buffer;
      source.connect(audioContext.destination);
      source.start(0);
    } catch (e) {
      console.error('ì•ˆë“œë¡œì´ë“œì—ì„œ ì˜¤ë””ì˜¤ ì‹œìŠ¤í…œ í™œì„±í™” ì‹¤íŒ¨:', e);
    }
  }
};

export default function VoiceChatPage() {
  const { language } = useLanguage()
  const [isDarkMode, setIsDarkMode] = useState(false)
  
  // ìŒì„± ëŒ€í™” ê´€ë ¨ ìƒíƒœ ì¶”ê°€
  const [isListening, setIsListening] = useState(false)
  const [isTalking, setIsTalking] = useState(false)
  const [transcript, setTranscript] = useState("")
  const [isProcessing, setIsProcessing] = useState(false)
  const [conversationActive, setConversationActive] = useState(false)
  const [isPaused, setIsPaused] = useState(false)
  const [errorMessage, setErrorMessage] = useState<string | null>(null)
  
  // Refs
  const audioContextRef = useRef<AudioContext | null>(null)
  const analyserRef = useRef<AnalyserNode | null>(null)
  const mediaStreamRef = useRef<MediaStream | null>(null)
  const silenceTimeoutRef = useRef<NodeJS.Timeout | null>(null)
  const recognitionRef = useRef<SpeechRecognition | null>(null)
  const audioPlayerRef = useRef<HTMLAudioElement | null>(null)
  const isListeningRef = useRef(isListening)
  const isProcessingRef = useRef(isProcessing)
  const isPausedRef = useRef(isPaused)
  const conversationActiveRef = useRef(conversationActive)

  // ìŒì„± ê°ì§€ ì„¤ì •
  const SILENCE_THRESHOLD = 15 // ë¬µìŒ ì„ê³„ê°’
  const SILENCE_DURATION = 1500 // ë¬µìŒ ì§€ì† ì‹œê°„ (1.5ì´ˆ)

  // ìŒì„± íŒŒí˜• ë°”ë“¤ì˜ ì• ë‹ˆë©”ì´ì…˜ì„ ìœ„í•œ ì„¤ì •
  const bars = Array.from({ length: 30 }) // 30ê°œì˜ íŒŒí˜• ë°”
  const getRandomHeight = () => Math.random() * 50 + 10 // 10-60px ì‚¬ì´ì˜ ëœë¤ ë†’ì´

  // SpeechRecognition ì„¤ì • í•¨ìˆ˜ ìˆ˜ì •
  const setupSpeechRecognition = () => {
    try {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition
      if (!SpeechRecognition) {
        throw new Error('Speech Recognition is not supported in this browser')
      }

      const recognition = new SpeechRecognition()
      
      recognition.lang = language === 'ko' ? 'ko-KR' : 'en-US'
      recognition.continuous = false  // ì—°ì† ì¸ì‹ ë¹„í™œì„±í™”
      recognition.interimResults = true
      
      recognition.onstart = () => {
        console.log('ìŒì„± ì¸ì‹ ì‹œì‘')
        setIsListening(true)
        
        // ëª¨ë°”ì¼ ê¸°ê¸°ì—ì„œ ìŒì„± ì¸ì‹ ì‹œì‘ ì‹œ ì¶”ê°€ ì²˜ë¦¬
        if (isMobile()) {
          console.log(`${isIOS() ? 'iOS' : 'ì•ˆë“œë¡œì´ë“œ'}ì—ì„œ ìŒì„± ì¸ì‹ ì‹œì‘ë¨`);
          
          // ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì¬ê°œ ì‹œë„
          if (audioContextRef.current && audioContextRef.current.state === 'suspended') {
            audioContextRef.current.resume().catch(err => {
              console.error('ëª¨ë°”ì¼ì—ì„œ AudioContext ì¬ê°œ ì‹¤íŒ¨:', err);
            });
            
            // ì•ˆë“œë¡œì´ë“œì—ì„œ ì¶”ê°€ ì²˜ë¦¬
            if (isAndroid() && audioContextRef.current) {
              unlockAudioContext(audioContextRef.current).catch(err => {
                console.error('ì•ˆë“œë¡œì´ë“œì—ì„œ AudioContext í™œì„±í™” ì‹¤íŒ¨:', err);
              });
            }
          }
        }
      }
      
      recognition.onresult = (event) => {
        const current = event.resultIndex
        const transcript = event.results[current][0].transcript
        
        console.log('ìŒì„± ì¸ì‹ ì¤‘:', transcript)
        setTranscript(transcript)
        
        if (event.results[current].isFinal) {
          console.log('ğŸ¤ ìµœì¢… ìŒì„± ì¸ì‹ ê²°ê³¼:', transcript)
          handleSpeechResult(transcript)
        }
      }
      
      recognition.onerror = (event) => {
        console.error('ìŒì„± ì¸ì‹ ì˜¤ë¥˜:', event.error)
        
        // ëª¨ë°”ì¼ì—ì„œ ì˜¤ë¥˜ ì²˜ë¦¬
        if (isMobile()) {
          console.log(`ëª¨ë°”ì¼ì—ì„œ ìŒì„± ì¸ì‹ ì˜¤ë¥˜ ë°œìƒ: ${event.error}`);
          
          // ì˜¤ë¥˜ ìœ í˜•ë³„ ë©”ì‹œì§€ ì„¤ì •
          let errorMsg = '';
          let shouldRetry = false;
          
          switch (event.error) {
            case 'not-allowed':
              errorMsg = isAndroid() 
                ? 'ì•ˆë“œë¡œì´ë“œì—ì„œëŠ” ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì•¼ í•©ë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.'
                : 'ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ì„¤ì •ì—ì„œ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.';
              shouldRetry = true;
              break;
            case 'network':
              errorMsg = 'ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.';
              shouldRetry = true;
              break;
            case 'aborted':
              // ì‚¬ìš©ìê°€ ì˜ë„ì ìœ¼ë¡œ ì¤‘ë‹¨í•œ ê²½ìš°ëŠ” ì˜¤ë¥˜ ë©”ì‹œì§€ í‘œì‹œí•˜ì§€ ì•ŠìŒ
              return;
            case 'audio-capture':
              errorMsg = 'ë§ˆì´í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë§ˆì´í¬ê°€ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.';
              break;
            case 'service-not-allowed':
              errorMsg = 'ìŒì„± ì¸ì‹ ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.';
              break;
            default:
              errorMsg = `ìŒì„± ì¸ì‹ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ${event.error}`;
          }
          
          // ì‚¬ìš©ìì—ê²Œ ì˜¤ë¥˜ ë©”ì‹œì§€ í‘œì‹œ
          setErrorMessage(errorMsg);
          
          // ì¬ì‹œë„ ì—¬ë¶€ ê²°ì •
          if (shouldRetry && conversationActiveRef.current) {
            setTimeout(() => {
              if (conversationActiveRef.current) {
                restartRecognition();
              }
            }, 1500);
            return;
          }
        }
        
        stopListening()
      }
      
      recognition.onend = () => {
        console.log('ìŒì„± ì¸ì‹ ì¢…ë£Œ')
        // ìŒì„± ì¸ì‹ì´ ì¢…ë£Œë˜ì—ˆì„ ë•Œ ìë™ìœ¼ë¡œ ì¬ì‹œì‘í•˜ì§€ ì•ŠìŒ
        // ëŒ€ì‹  handleSpeechResultì—ì„œ AI ì‘ë‹µ í›„ restartRecognitionì„ í˜¸ì¶œ
      }

      recognitionRef.current = recognition
      return recognition
    } catch (error) {
      console.error('Speech Recognition ì„¤ì • ì˜¤ë¥˜:', error)
      return null
    }
  }

  // handleSpeechResult í•¨ìˆ˜ ìˆ˜ì •
  const handleSpeechResult = async (text: string) => {
    if (!text.trim() || isProcessing) return
    
    console.log('ìŒì„± ì¸ì‹ ê²°ê³¼ ì²˜ë¦¬ ì‹œì‘, conversationActive:', conversationActiveRef.current);
    if (!conversationActiveRef.current) {
      console.log('ëŒ€í™”ê°€ í™œì„±í™”ë˜ì§€ ì•Šì•„ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ');
      return;
    }
    
    setIsProcessing(true)
    try {
      // ìŒì„± ì¸ì‹ ì¼ì‹œ ì¤‘ì§€ (but keep isListening true)
      if (recognitionRef.current) {
        try {
          recognitionRef.current.stop();
          setIsPaused(true);
          console.log('ìŒì„± ì¸ì‹ ì¼ì‹œ ì¤‘ì§€: recognition paused during AI response');
          console.log('isPaused ìƒíƒœë¥¼ trueë¡œ ì„¤ì •');
        } catch (err) {
          console.error('ìŒì„± ì¸ì‹ ì¤‘ì§€ ì¤‘ ì˜¤ë¥˜:', err);
        }
      }

      const response = await fetch('/api/voice-chat', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ text })
      })

      if (!response.ok) throw new Error('API ì‘ë‹µ ì˜¤ë¥˜')

      const audioBlob = await response.blob()
      await playAudio(audioBlob)

      console.log('AI ì‘ë‹µ ì¬ìƒ ì™„ë£Œ');

    } catch (error) {
      if (error instanceof Error) {
        console.warn('ìŒì„± ì²˜ë¦¬ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤:', error.message)
      }
    } finally {
      setIsProcessing(false)
      
      // isProcessingì´ falseë¡œ ì„¤ì •ëœ í›„ì— ì¬ì‹œì‘ ë¡œì§ ì‹¤í–‰
      if (conversationActiveRef.current) {
        console.log('finally ë¸”ë¡ì—ì„œ ì¬ì‹œì‘ ë¡œì§ ì‹¤í–‰, conversationActive:', conversationActiveRef.current);
        // ìƒíƒœ ì—…ë°ì´íŠ¸ê°€ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì´ë£¨ì–´ì§€ë¯€ë¡œ, ì•½ê°„ì˜ ì§€ì—° í›„ ì¬ì‹œì‘
        setTimeout(() => {
          console.log('finally ë¸”ë¡ì˜ íƒ€ì„ì•„ì›ƒì—ì„œ ì¬ì‹œì‘ ì‹œë„');
          console.log('ì¬ì‹œì‘ ì§ì „ ìƒíƒœ - conversationActive:', conversationActiveRef.current, 'isPaused:', isPaused);
          restartRecognition();
        }, 800); // 0.8ì´ˆë¡œ ì¤„ì„
      } else {
        console.log('ëŒ€í™”ê°€ í™œì„±í™”ë˜ì§€ ì•Šì•„ ì¬ì‹œì‘í•˜ì§€ ì•ŠìŒ, conversationActive:', conversationActiveRef.current);
      }
    }
  }

  // startListening í•¨ìˆ˜ ìˆ˜ì • - ì•ˆë“œë¡œì´ë“œ ê¸°ê¸°ì—ì„œ ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ í™œì„±í™” ì¶”ê°€
  const startListening = async () => {
    try {
      console.log('ëŒ€í™” ì‹œì‘í•˜ê¸° ë²„íŠ¼ í´ë¦­ë¨');
      setErrorMessage(null); // ì˜¤ë¥˜ ë©”ì‹œì§€ ì´ˆê¸°í™”
      setConversationActive(true);
      conversationActiveRef.current = true; // ì¦‰ì‹œ ref ì—…ë°ì´íŠ¸
      console.log('conversationActive ìƒíƒœë¥¼ trueë¡œ ì„¤ì • (ref:', conversationActiveRef.current, ')');
      // ê¸°ì¡´ ë¦¬ì†ŒìŠ¤ ì •ë¦¬
      if (recognitionRef.current) {
        recognitionRef.current.stop()
        recognitionRef.current = null
      }

      // Speech Recognition ìƒˆë¡œ ì„¤ì • ë° ì‹œì‘
      const recognition = setupSpeechRecognition()
      if (recognition) {
        recognition.start()
      }

      // ì˜¤ë””ì˜¤ ë¶„ì„ ì„¤ì • - ëª¨ë°”ì¼ ê¸°ê¸°ì— ìµœì í™”ëœ ì„¤ì •
      const constraints = {
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      };
      
      // ëª¨ë°”ì¼ ê¸°ê¸°ì—ì„œ ì¶”ê°€ ì„¤ì •
      if (isMobile()) {
        console.log('ëª¨ë°”ì¼ ê¸°ê¸°ì—ì„œ ë§ˆì´í¬ ì ‘ê·¼ ì‹œë„');
        // ëª¨ë°”ì¼ ê¸°ê¸°ì—ì„œëŠ” ê¸°ë³¸ ì„¤ì • ì‚¬ìš©
      }
      
      const stream = await navigator.mediaDevices.getUserMedia(constraints)
      mediaStreamRef.current = stream
      
      // ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì„¤ì • ë¶€ë¶„ ìˆ˜ì •
      const AudioContextClass = window.AudioContext || (window as any).webkitAudioContext;
      const audioContext = new AudioContextClass();
      
      // ëª¨ë°”ì¼ ê¸°ê¸°ì—ì„œ ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ìƒíƒœ í™•ì¸ ë° ì¬ê°œ
      if (audioContext.state === 'suspended') {
        try {
          await audioContext.resume();
          console.log('AudioContext ì¬ê°œë¨');
          
          // ëª¨ë°”ì¼ ê¸°ê¸°ì—ì„œëŠ” ì¶”ê°€ ì²˜ë¦¬
          if (isMobile()) {
            if (isAndroid()) {
              // ì•ˆë“œë¡œì´ë“œì—ì„œ ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ í™œì„±í™”
              await unlockAudioContext(audioContext);
            } else {
              // iOS ë° ê¸°íƒ€ ëª¨ë°”ì¼ ë¸Œë¼ìš°ì €ì—ì„œëŠ” ì‚¬ìš©ì ìƒí˜¸ì‘ìš© í›„ ì§§ì€ ì†Œë¦¬ë¥¼ ì¬ìƒí•˜ì—¬ ì˜¤ë””ì˜¤ ì‹œìŠ¤í…œ í™œì„±í™”
              try {
                const silentContext = new AudioContextClass();
                const buffer = silentContext.createBuffer(1, 1, 22050);
                const source = silentContext.createBufferSource();
                source.buffer = buffer;
                source.connect(silentContext.destination);
                source.start(0);
                console.log('ëª¨ë°”ì¼ ê¸°ê¸°ì—ì„œ ì˜¤ë””ì˜¤ ì‹œìŠ¤í…œ í™œì„±í™” ì‹œë„');
              } catch (silentErr) {
                console.error('ì˜¤ë””ì˜¤ ì‹œìŠ¤í…œ í™œì„±í™” ì‹¤íŒ¨:', silentErr);
              }
            }
          }
        } catch (err) {
          console.error('AudioContext ì¬ê°œ ì‹¤íŒ¨:', err);
        }
      }
      
      const analyser = audioContext.createAnalyser()
      const source = audioContext.createMediaStreamSource(stream)
      
      analyser.fftSize = 2048
      source.connect(analyser)
      
      audioContextRef.current = audioContext
      analyserRef.current = analyser
      
      setIsListening(true)
      monitorAudioLevel()
      
    } catch (error) {
      console.error('ìŒì„± ì¸ì‹ ì‹œì‘ ì˜¤ë¥˜:', error)
      stopListening()
    }
  }

  const monitorAudioLevel = () => {
    if (!analyserRef.current) return

    const analyser = analyserRef.current
    const dataArray = new Uint8Array(analyser.frequencyBinCount)
    
    const checkLevel = () => {
      if (!isListening) return
      
      analyser.getByteFrequencyData(dataArray)
      const average = dataArray.reduce((acc, val) => acc + val, 0) / dataArray.length
      
      if (average > SILENCE_THRESHOLD) {
        // ìŒì„± ê°ì§€ë¨
        setIsTalking(true)
        if (silenceTimeoutRef.current) {
          clearTimeout(silenceTimeoutRef.current)
          silenceTimeoutRef.current = null
        }
      } else if (isTalking) {
        // ë¬µìŒ ê°ì§€
        if (!silenceTimeoutRef.current) {
          silenceTimeoutRef.current = setTimeout(() => {
            handleSpeechEnd()
          }, SILENCE_DURATION)
        }
      }
      
      requestAnimationFrame(checkLevel)
    }
    
    checkLevel()
  }

  const handleSpeechEnd = async () => {
    setIsTalking(false)
    // transcriptê°€ ì´ë¯¸ handleSpeechResultì—ì„œ ì²˜ë¦¬ë˜ì—ˆìœ¼ë¯€ë¡œ
    // ì—¬ê¸°ì„œëŠ” ìƒíƒœë§Œ ì´ˆê¸°í™”
    setTranscript("")
  }

  // stopListening í•¨ìˆ˜ ìˆ˜ì •
  const stopListening = () => {
    try {
      setConversationActive(false); // ëŒ€í™” í™œì„±í™” ìƒíƒœë¥¼ falseë¡œ ì„¤ì •
      conversationActiveRef.current = false; // ì¦‰ì‹œ ref ì—…ë°ì´íŠ¸
      console.log('ëŒ€í™” ì¢…ë£Œ: conversationActiveë¥¼ falseë¡œ ì„¤ì •');
      setIsProcessing(false) // ë¨¼ì € ì²˜ë¦¬ ìƒíƒœë¥¼ falseë¡œ ì„¤ì •

      // 1. í˜„ì¬ ì¬ìƒ ì¤‘ì¸ ì˜¤ë””ì˜¤ ì¤‘ì§€ - ì—ëŸ¬ ì²˜ë¦¬ ì¶”ê°€
      if (audioPlayerRef.current) {
        try {
          audioPlayerRef.current.pause();
          audioPlayerRef.current.src = '';
          audioPlayerRef.current = null;
        } catch (err) {
          // ì˜¤ë””ì˜¤ ì¤‘ì§€ ì¤‘ ì—ëŸ¬ëŠ” ë¬´ì‹œ
        }
      }

      // 2. Web Speech Recognition ì¤‘ì§€
      if (recognitionRef.current) {
        try {
          recognitionRef.current.stop()
          // ë¹ˆ í•¨ìˆ˜ë¡œ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì´ˆê¸°í™”
          recognitionRef.current.onend = () => {};
          recognitionRef.current.onresult = () => {};
          recognitionRef.current.onerror = () => {};
          recognitionRef.current = null
        } catch (err) {
          // Recognition ì¤‘ì§€ ì¤‘ ì—ëŸ¬ëŠ” ë¬´ì‹œ
        }
      }

      // 3. ë¯¸ë””ì–´ ìŠ¤íŠ¸ë¦¼ íŠ¸ë™ ì¤‘ì§€
      if (mediaStreamRef.current) {
        try {
          mediaStreamRef.current.getTracks().forEach(track => {
            track.stop()
            mediaStreamRef.current?.removeTrack(track)
          })
          mediaStreamRef.current = null
        } catch (err) {
          // ë¯¸ë””ì–´ ìŠ¤íŠ¸ë¦¼ ì¤‘ì§€ ì¤‘ ì—ëŸ¬ëŠ” ë¬´ì‹œ
        }
      }

      // 4. AudioContext ì •ë¦¬
      if (audioContextRef.current) {
        try {
          audioContextRef.current.close()
          audioContextRef.current = null
        } catch (err) {
          // AudioContext ì¤‘ì§€ ì¤‘ ì—ëŸ¬ëŠ” ë¬´ì‹œ
        }
      }

      // 5. AnalyserNode ì—°ê²° í•´ì œ
      if (analyserRef.current) {
        try {
          analyserRef.current.disconnect()
          analyserRef.current = null
        } catch (err) {
          // Analyser ì—°ê²° í•´ì œ ì¤‘ ì—ëŸ¬ëŠ” ë¬´ì‹œ
        }
      }

      // 6. íƒ€ì´ë¨¸ ì •ë¦¬
      if (silenceTimeoutRef.current) {
        clearTimeout(silenceTimeoutRef.current)
        silenceTimeoutRef.current = null
      }

      // 7. ìƒíƒœ ì´ˆê¸°í™”
      setIsListening(false)
      setIsTalking(false)
      setTranscript("")

      console.log('ìŒì„± ëŒ€í™”ê°€ ì•ˆì „í•˜ê²Œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.')
    } catch (error) {
      console.warn('ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘ ì¼ë¶€ ì‘ì—…ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤:', error)
    }
  }

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
  useEffect(() => {
    return () => {
      stopListening()
    }
  }, [])

  // í˜ì´ì§€ ì´ë™ ì‹œ ì •ë¦¬ë¥¼ ìœ„í•œ ì¶”ê°€
  useEffect(() => {
    const handleBeforeUnload = () => {
      stopListening()
    }

    window.addEventListener('beforeunload', handleBeforeUnload)
    return () => {
      window.removeEventListener('beforeunload', handleBeforeUnload)
    }
  }, [])

  // playAudio í•¨ìˆ˜ ìˆ˜ì • - ì•ˆë“œë¡œì´ë“œ ê¸°ê¸°ì—ì„œ ì˜¤ë””ì˜¤ ì¬ìƒ ë¬¸ì œ í•´ê²°
  const playAudio = async (audioBlob: Blob): Promise<void> => {
    return new Promise((resolve, reject) => {
      try {
        // ì´ì „ ì˜¤ë””ì˜¤ ì •ë¦¬
        if (audioPlayerRef.current) {
          try {
            audioPlayerRef.current.pause();
            audioPlayerRef.current.src = '';
          } catch (err) {
            // ì´ì „ ì˜¤ë””ì˜¤ ì¤‘ì§€ ì¤‘ ì—ëŸ¬ëŠ” ë¬´ì‹œ
          }
        }
        
        // ì˜¤ë””ì˜¤ URL ìƒì„± ë° ì˜¤ë””ì˜¤ ê°ì²´ ì„¤ì •
        const audioUrl = URL.createObjectURL(audioBlob)
        const audio = new Audio(audioUrl)
        audioPlayerRef.current = audio;
        
        // ëª¨ë°”ì¼ ê¸°ê¸°ì—ì„œ ì˜¤ë””ì˜¤ ì¬ìƒ ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ì„¤ì •
        audio.preload = 'auto';
        
        // ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì„¤ì •
        audio.onended = () => {
          URL.revokeObjectURL(audioUrl)
          audioPlayerRef.current = null;
          resolve();
        }
        
        audio.onerror = (e) => {
          console.error('ì˜¤ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜:', e);
          URL.revokeObjectURL(audioUrl)
          audioPlayerRef.current = null;
          reject(new Error('ì˜¤ë””ì˜¤ ì¬ìƒì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.'))
        }
        
        // ëª¨ë°”ì¼ ê¸°ê¸°ì—ì„œ ì˜¤ë””ì˜¤ ì¬ìƒ ì „ ì¶”ê°€ ì„¤ì •
        if (isMobile()) {
          console.log('ëª¨ë°”ì¼ì—ì„œ ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œë„...');
          
          // ëª¨ë°”ì¼ ê¸°ê¸°ì—ì„œ ê³µí†µ ì„¤ì •
          audio.setAttribute('playsinline', '');
          audio.setAttribute('webkit-playsinline', '');
          
          // ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì¬ê°œ ì‹œë„ (ëª¨ë°”ì¼ ë¸Œë¼ìš°ì €ì—ì„œ í•„ìš”í•  ìˆ˜ ìˆìŒ)
          if (audioContextRef.current && audioContextRef.current.state === 'suspended') {
            try {
              audioContextRef.current.resume().then(() => {
                // ì•ˆë“œë¡œì´ë“œì—ì„œ ì¶”ê°€ ì²˜ë¦¬
                if (isAndroid() && audioContextRef.current) {
                  unlockAudioContext(audioContextRef.current).then(() => {
                    // ì•ˆë“œë¡œì´ë“œ í¬ë¡¬ì—ì„œëŠ” ì˜¤ë””ì˜¤ ìš”ì†Œì— ì§ì ‘ í´ë¦­ ì´ë²¤íŠ¸ ì‹œë®¬ë ˆì´ì…˜
                    try {
                      const touchEvent = new TouchEvent('touchend');
                      audio.dispatchEvent(touchEvent);
                    } catch (touchErr) {
                      console.error('í„°ì¹˜ ì´ë²¤íŠ¸ ì‹œë®¬ë ˆì´ì…˜ ì‹¤íŒ¨:', touchErr);
                    }
                  });
                }
              });
            } catch (resumeErr) {
              console.error('AudioContext ì¬ê°œ ì‹¤íŒ¨:', resumeErr);
            }
          }
          
          // ì§€ì—° í›„ ì¬ìƒ ì‹œë„
          setTimeout(() => {
            audio.play().catch(err => {
              console.error('ì˜¤ë””ì˜¤ ì¬ìƒ ì²« ì‹œë„ ì‹¤íŒ¨:', err);
              
              // ì¬ì‹œë„
              setTimeout(() => {
                audio.play().catch(retryErr => {
                  console.error('ì˜¤ë””ì˜¤ ì¬ìƒ ì¬ì‹œë„ ì‹¤íŒ¨:', retryErr);
                  reject(new Error('ì˜¤ë””ì˜¤ ì¬ìƒì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'));
                });
              }, 300);
            });
          }, 500);
        } else {
          // ë°ìŠ¤í¬í†±ì—ì„œëŠ” ë°”ë¡œ ì¬ìƒ
          audio.play().catch(err => {
            console.error('ì˜¤ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨:', err);
            reject(new Error('ì˜¤ë””ì˜¤ ì¬ìƒì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'));
          });
        }
      } catch (error) {
        reject(new Error('ì˜¤ë””ì˜¤ ì¬ìƒ ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'))
      }
    })
  }

  // ìƒíƒœ ë³€ê²½ ì‹œ ref ì—…ë°ì´íŠ¸
  useEffect(() => {
    isListeningRef.current = isListening
  }, [isListening])

  useEffect(() => {
    isProcessingRef.current = isProcessing
  }, [isProcessing])

  useEffect(() => {
    isPausedRef.current = isPaused
  }, [isPaused])

  useEffect(() => {
    conversationActiveRef.current = conversationActive;
  }, [conversationActive]);

  // restartRecognition í•¨ìˆ˜ ìˆ˜ì •
  const restartRecognition = () => {
    console.log('ì¬ì‹œì‘: Speech Recognition ì¬ì„¤ì • ì‹œë„');
    console.log('í˜„ì¬ ìƒíƒœ - conversationActive:', conversationActiveRef.current, 'isPaused:', isPaused, 'isProcessing:', isProcessing);
    
    if (!conversationActiveRef.current) {
      console.log('ëŒ€í™”ê°€ í™œì„±í™”ë˜ì§€ ì•Šì•„ ì¬ì‹œì‘í•˜ì§€ ì•ŠìŒ');
      return;
    }
    
    // ìƒíƒœ ì—…ë°ì´íŠ¸ë¥¼ ë¨¼ì € ìˆ˜í–‰
    setIsPaused(false);
    
    // ì•½ê°„ì˜ ì§€ì—° í›„ ì‹¤ì œ ì¬ì‹œì‘ ìˆ˜í–‰ (ìƒíƒœ ì—…ë°ì´íŠ¸ê°€ ë°˜ì˜ë˜ë„ë¡)
    setTimeout(() => {
      try {
        console.log('ì¬ì‹œì‘ íƒ€ì„ì•„ì›ƒ ì‹¤í–‰ë¨');
        
        // ëª¨ë°”ì¼ ê¸°ê¸°ì—ì„œ ì¬ì‹œì‘ ì‹œ ì¶”ê°€ ì²˜ë¦¬
        if (isMobile()) {
          if (isIOS()) {
            console.log('iOSì—ì„œ ìŒì„± ì¸ì‹ ì¬ì‹œì‘ ì‹œë„');
            // iOSì—ì„œëŠ” ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì¬ê°œ ì‹œë„
            if (audioContextRef.current && audioContextRef.current.state === 'suspended') {
              try {
                audioContextRef.current.resume();
              } catch (err) {
                console.error('iOSì—ì„œ AudioContext ì¬ê°œ ì‹¤íŒ¨:', err);
              }
            }
          } else if (isAndroid()) {
            console.log('ì•ˆë“œë¡œì´ë“œì—ì„œ ìŒì„± ì¸ì‹ ì¬ì‹œì‘ ì‹œë„');
            // ì•ˆë“œë¡œì´ë“œì—ì„œëŠ” ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ í™œì„±í™” ì‹œë„
            if (audioContextRef.current) {
              try {
                unlockAudioContext(audioContextRef.current);
              } catch (err) {
                console.error('ì•ˆë“œë¡œì´ë“œì—ì„œ AudioContext í™œì„±í™” ì‹¤íŒ¨:', err);
              }
            }
          }
        }
        
        // ê¸°ì¡´ ì¸ìŠ¤í„´ìŠ¤ê°€ ìˆìœ¼ë©´ ì •ë¦¬
        if (recognitionRef.current) {
          try {
            recognitionRef.current.stop();
            recognitionRef.current.onend = () => {};
            recognitionRef.current.onresult = () => {};
            recognitionRef.current.onerror = () => {};
            recognitionRef.current = null;
            console.log('ê¸°ì¡´ recognition ì¸ìŠ¤í„´ìŠ¤ ì •ë¦¬ë¨');
          } catch (err) {
            console.log('ê¸°ì¡´ recognition ì¸ìŠ¤í„´ìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜:', err);
          }
        }
        
        // ìƒˆ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° ì‹œì‘
        const recognition = setupSpeechRecognition();
        if (recognition) {
          console.log('ìƒˆ recognition ì¸ìŠ¤í„´ìŠ¤ ìƒì„±ë¨, ì‹œì‘ ì‹œë„...');
          recognition.start();
          recognitionRef.current = recognition;
          setIsListening(true); // ëª…ì‹œì ìœ¼ë¡œ isListening ì„¤ì •
          console.log('ì¬ì‹œì‘: Speech Recognition ì‹œì‘ë¨');
        } else {
          console.warn('ì¬ì‹œì‘: Speech Recognition ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨');
        }
      } catch (error) {
        console.error('ìŒì„± ì¸ì‹ ì¬ì‹œì‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:', error);
      }
    }, 200); // 0.2ì´ˆë¡œ ì¤„ì„
  };

  return (
    <div className={`min-h-screen flex flex-col ${isDarkMode ? 'bg-gray-900 text-white' : 'bg-white'}`}>
      {/* í—¤ë” */}
      <header className={`fixed top-0 left-0 right-0 z-50 border-b ${
        isDarkMode ? 'bg-gray-900 border-gray-700' : 'bg-white'
      }`}>
        <div className="max-w-5xl mx-auto px-4">
          <div className="flex items-center justify-between py-4">
            <Link 
              href="/chat" 
              className={`p-2 rounded-full ${
                isDarkMode ? 'hover:bg-gray-700' : 'hover:bg-gray-100'
              } flex items-center gap-2`}
            >
              <ArrowLeft className="w-5 h-5" />
              <span>ì±„íŒ…ìœ¼ë¡œ ëŒì•„ê°€ê¸°</span>
            </Link>
            <button
              onClick={() => setIsDarkMode(!isDarkMode)}
              className={`p-2 rounded-full ${
                isDarkMode ? 'hover:bg-gray-700' : 'hover:bg-gray-100'
              }`}
            >
              {isDarkMode ? <Sun className="w-5 h-5" /> : <Moon className="w-5 h-5" />}
            </button>
          </div>
        </div>
      </header>

      {/* ë©”ì¸ ì»¨í…ì¸  */}
      <main className="flex-1 max-w-5xl mx-auto w-full mt-20 p-8">
        <div className="flex flex-col items-center justify-center min-h-[calc(100vh-160px)]">
          <div className="w-32 h-32 relative rounded-full overflow-hidden mb-8 shadow-xl">
            <Image
              src="/profile.png"
              alt={translate('name', language)}
              layout="fill"
              className="object-cover"
            />
          </div>

          {/* ìŒì„± íŒŒí˜• ì• ë‹ˆë©”ì´ì…˜ - ìƒíƒœì— ë”°ë¼ ë‹¤ë¥´ê²Œ í‘œì‹œ */}
          <div className="flex items-center justify-center gap-1 mb-8 h-32">
            {bars.map((_, i) => (
              <motion.div
                key={i}
                className={`w-1 rounded-full ${
                  isTalking 
                    ? 'bg-green-500' 
                    : isDarkMode ? 'bg-blue-400' : 'bg-blue-500'
                }`}
                animate={{
                  height: isTalking 
                    ? [getRandomHeight() * 1.5, getRandomHeight() * 1.5] 
                    : isListening 
                      ? [getRandomHeight(), getRandomHeight()]
                      : "20px"
                }}
                transition={{
                  duration: isTalking ? 0.3 : 1.5,
                  repeat: Infinity,
                  repeatType: "reverse",
                  delay: i * 0.05,
                }}
              />
            ))}
          </div>

          {/* ìƒíƒœ ë©”ì‹œì§€ */}
          <div className={`text-center max-w-md mx-auto ${isDarkMode ? 'text-gray-300' : 'text-gray-600'}`}>
            <h2 className="text-2xl font-bold mb-4">
              {errorMessage 
                ? "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤"
                : isListening 
                  ? isTalking 
                    ? "ìŒì„±ì„ ì¸ì‹í•˜ê³  ìˆìŠµë‹ˆë‹¤..."
                    : "ë§ì”€í•´ ì£¼ì„¸ìš”"
                  : `${translate('name', language)}${translate('cloneTitle', language)}ì™€ ìŒì„±ìœ¼ë¡œ ëŒ€í™”í•´ë³´ì„¸ìš”`}
            </h2>
            <p className={`text-lg ${errorMessage ? 'text-red-500 font-medium' : 'opacity-75'}`}>
              {errorMessage 
                ? errorMessage
                : isListening 
                  ? isMobile() 
                    ? isIOS() 
                      ? "iOSì—ì„œëŠ” ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì•¼ í•©ë‹ˆë‹¤"
                      : "ì•ˆë“œë¡œì´ë“œì—ì„œëŠ” ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì•¼ í•©ë‹ˆë‹¤"
                    : "ìë™ìœ¼ë¡œ ìŒì„±ì„ ê°ì§€í•˜ì—¬ ëŒ€í™”í•©ë‹ˆë‹¤"
                  : "ììœ ë¡­ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”. ìë™ìœ¼ë¡œ ìŒì„±ì„ ì¸ì‹í•˜ì—¬ ëŒ€í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤."}
            </p>
          </div>

          {/* ëŒ€í™” ì‹œì‘/ì¢…ë£Œ ë²„íŠ¼ */}
          <motion.button
            onClick={isListening ? stopListening : startListening}
            className={`mt-12 px-8 py-4 rounded-full text-white font-medium
              ${isListening 
                ? 'bg-red-500 hover:bg-red-600' 
                : isDarkMode 
                  ? 'bg-blue-600 hover:bg-blue-700' 
                  : 'bg-blue-500 hover:bg-blue-600'
              } transform transition-all duration-200 hover:scale-105`}
            whileTap={{ scale: 0.95 }}
          >
            {isListening ? 'ëŒ€í™” ì¢…ë£Œí•˜ê¸°' : 'ëŒ€í™” ì‹œì‘í•˜ê¸°'}
          </motion.button>
        </div>
      </main>
    </div>
  )
} 